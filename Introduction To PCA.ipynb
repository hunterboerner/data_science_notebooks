{
 "metadata": {
  "name": "",
  "signature": "sha256:1ef2f73746c06e976ba7b4c0a707e9cf245298ceddde9f814313ae6d2defa9a8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Generate data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(1)\n",
      "X = np.dot(np.random.random(size=(2, 2)), np.random.normal(size=(2, 200))).T\n",
      "plt.plot(X[:, 0], X[:, 1], 'ob')\n",
      "plt.axis('equal')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Perform PCA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import PCA\n",
      "pca = PCA(n_components=2)\n",
      "pca.fit(X)\n",
      "\n",
      "# Percentage of variance explained by each of the selected components\n",
      "print(pca.explained_variance_ratio_)\n",
      "print(pca.components_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(X[:, 0], X[:, 1], 'ob', alpha=0.3)\n",
      "plt.axis('equal')\n",
      "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
      "    v = vector *3 * np.sqrt(length)\n",
      "    plt.plot([0, v[0]], [0, v[1]], '-r', lw=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_pca = pca.fit_transform(X)\n",
      "plt.figure(figsize=(4,4))\n",
      "plt.scatter(X_pca[:,0], X_pca[:,1], alpha=0.3)\n",
      "plt.axis('equal');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Keep the components that explain most of the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = PCA(0.95)\n",
      "X_trans = clf.fit_transform(X)\n",
      "print(X.shape)\n",
      "print(X_trans.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Transform data back to its original space\n",
      "X_new = clf.inverse_transform(X_trans)\n",
      "\n",
      "plt.plot(X[:, 0], X[:, 1], 'ob', alpha=0.2)\n",
      "plt.plot(X_new[:, 0], X_new[:, 1], 'or', alpha=0.9)\n",
      "plt.axis('equal');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Image compression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Download Olivetti faces data is available in scikit-learn.\n",
      "from sklearn.datasets import fetch_olivetti_faces\n",
      "oliv=fetch_olivetti_faces()\n",
      "print oliv.data.shape #tells us there are 400 images that are 64 x 64 (4096) pixels each"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Setup a figure 6 inches by 6 inches\n",
      "fig = plt.figure(figsize=(6,6))\n",
      "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
      "\n",
      "# plot the faces, each image is 64 by 64 pixels\n",
      "for i in range(64):\n",
      "    ax = fig.add_subplot(8, 8, i+1, xticks=[], yticks=[])\n",
      "    ax.imshow(oliv.images[i], cmap=plt.cm.bone, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Compressed images down to a 8x8 (64) pixel images.\n",
      "X,y=oliv.data, oliv.target\n",
      "pca_oliv = PCA(n_components = 64)\n",
      "X_proj = pca_oliv.fit_transform(X)\n",
      "print X_proj.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compressing a 64x64 pixel image down to an 8x8 image still retains about 89.7% of the varianc\n",
      "print np.cumsum(pca_oliv.explained_variance_ratio_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Reconstruct the images using the new reduced dataset. In other words, we transformed the \n",
      "#64x64 pixel images into 8x8 images. Now to visualize how these images look we need to inverse transform the 8x8 images\n",
      "#back to 64x64 dimension. Note that we're not reverting back to the original data, we're simply going back to the \n",
      "#actual dimension of the original images so we can visualize them.\n",
      "\n",
      "X_inv_proj = pca_oliv.inverse_transform(X_proj)\n",
      "\n",
      "#reshaping as 400 images of 64x64 dimension\n",
      "X_proj_img = np.reshape(X_inv_proj,(400,64,64))\n",
      "\n",
      "#Setup a figure\n",
      "fig = plt.figure(figsize=(6,6))\n",
      "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
      "\n",
      "# plot the faces, each image is 64 by 64 dimension but 8x8 pixels\n",
      "for i in range(64):\n",
      "    ax = fig.add_subplot(8, 8, i+1, xticks=[], yticks=[])\n",
      "    ax.imshow(X_proj_img[i], cmap=plt.cm.bone, interpolation='nearest')\n",
      "    \n",
      "# This is not bad at all, the image still looks pretty good but the finer details are missing, which is okay considering \n",
      "# we've reduced dimensionality by 64 times."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}